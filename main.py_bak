import os
import random
import json
import asyncio
from typing import List, Dict, Optional
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from supabase import create_client, Client
from dotenv import load_dotenv
import httpx
import logging
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from asyncio import Semaphore

# Load environment variables from .env file
load_dotenv()

# ---------------------- Configuration and Initialization ----------------------

# Load environment variables
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
SUPABASE_SECRET_KEY = os.getenv("SUPABASE_SECRET_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_API_ENDPOINT = "https://api.groq.com/openai/v1/chat/completions"  # Hardcoded as per request
REDIS_PASSWORD = os.getenv("REDIS_PASSWORD")
REDIS_ENDPOINT = os.getenv("REDIS_ENDPOINT")
E2B_API_KEY = os.getenv("E2B_API_KEY")

# Check for required environment variables
required_env_vars = [SUPABASE_URL, SUPABASE_KEY, GROQ_API_KEY]
if not all(required_env_vars):
    missing_vars = []
    if not SUPABASE_URL:
        missing_vars.append("SUPABASE_URL")
    if not SUPABASE_KEY:
        missing_vars.append("SUPABASE_KEY")
    if not GROQ_API_KEY:
        missing_vars.append("GROQ_API_KEY")
    raise EnvironmentError(f"Missing required environment variables: {', '.join(missing_vars)}")

# Initialize Supabase client
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Initialize FastAPI app
app = FastAPI(title="LLM-Based Multi-Agent Simulation")

# Initialize Rate Limiter (Moderate limit: 60 requests per minute)
limiter = Limiter(key_func=get_remote_address, default_limits=["60/minute"])
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# Setup logging
logger = logging.getLogger("simulation_app")
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
formatter = logging.Formatter(
    '[%(asctime)s] [%(levelname)s] %(message)s'
)
handler.setFormatter(formatter)
logger.addHandler(handler)

# Simulation Configuration
GRID_SIZE = 50  # Updated to match the paper's field size
NUM_AGENTS = 10  # Total number of agents
MAX_STEPS = 100
CHEBYSHEV_DISTANCE = 5
LLM_MODEL = "llama-3.2-90b-vision-preview"
LLM_MAX_TOKENS = 2048  # As per user request
LLM_TEMPERATURE = 0.7

# Concurrency Control
LLM_CONCURRENCY_LIMIT = 1  # Set to 1 to ensure requests are well-paced
llm_semaphore = Semaphore(LLM_CONCURRENCY_LIMIT)

# ---------------------- Prompt Templates ----------------------

GRID_DESCRIPTION = (
    "The field size is 50 x 50 with periodic boundary conditions, and there are a total of 10 agents. "
    "You are free to move around the field and converse with other agents."
)

# Message Generation Prompt Template
MESSAGE_GENERATION_PROMPT = """
[INST]  
You are agent{agentId} at position ({x}, {y}). {grid_description} You have a summary memory of the situation so far: {memory}. You received messages from the surrounding agents: {messages}. Based on the above, you send a message to the surrounding agents. Your message will reach agents up to distance {distance} away. What message do you send? [/INST]
"""

# Memory Generation Prompt Template
MEMORY_GENERATION_PROMPT = """
[INST]  
You are agent{agentId} at position ({x}, {y}). {grid_description} You have a summary memory of the situation so far: {memory}. You received messages from the surrounding agents: {messages}. Based on the above, summarize the situation you and the other agents have been in so far for you to remember. [/INST]
"""

# Movement Generation Prompt Template
MOVEMENT_GENERATION_PROMPT = """
[INST]  
You are agent{agentId} at position ({x}, {y}). {grid_description} You have a summary memory of the situation so far: {memory}. Based on the above, what is your next move command? Choose only one of the following: ["x+1", "x-1", "y+1", "y-1", "stay"] [/INST]
"""

# ---------------------- Pydantic Models ----------------------

class LLMResponse(BaseModel):
    message: Optional[str] = ""
    memory: Optional[str] = ""
    movement: Optional[str] = "stay"

class StepRequest(BaseModel):
    steps: int  # Number of steps to perform

# ---------------------- Helper Functions ----------------------

def chebyshev_distance(x1: int, y1: int, x2: int, y2: int) -> int:
    """
    Calculate the Chebyshev distance between two points on a grid with periodic boundary conditions.
    """
    dx = min(abs(x1 - x2), GRID_SIZE - abs(x1 - x2))
    dy = min(abs(y1 - y2), GRID_SIZE - abs(y1 - y2))
    return max(dx, dy)

def get_nearby_agents(agent: Dict, agents: List[Dict]) -> List[Dict]:
    """
    Get a list of agents that are within CHEBYSHEV_DISTANCE of the given agent.
    """
    nearby = []
    for other in agents:
        if other['id'] == agent['id']:
            continue
        distance = chebyshev_distance(agent['x'], agent['y'], other['x'], other['y'])
        if distance <= CHEBYSHEV_DISTANCE:
            nearby.append(other)
    return nearby

def construct_prompt(template: str, agent: Dict, messages: List[str]) -> str:
    """
    Fill in the prompt template with the agent's current data and received messages.
    """
    # Join messages into a single string separated by newlines
    messages_str = "\n".join(messages)
    return template.format(
        agentId=agent['id'],
        x=agent['x'],
        y=agent['y'],
        grid_description=GRID_DESCRIPTION,
        memory=agent.get('memory', ""),
        messages=messages_str,
        distance=CHEBYSHEV_DISTANCE
    )

async def send_llm_request(prompt: str) -> Optional[LLMResponse]:
    """
    Send a request to the GROQ API and parse the response into an LLMResponse object.
    """
    async with llm_semaphore:
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {GROQ_API_KEY}'
        }
        body = {
            "model": LLM_MODEL,
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "You are a simulation agent that responds in JSON format.\n"
                        f"The JSON response must follow this schema: {LLMResponse.schema_json(indent=2)}"
                    ),
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
            "max_tokens": LLM_MAX_TOKENS,
            "temperature": LLM_TEMPERATURE,
            # Assuming GROQ API supports response_format similar to OpenAI's
            "response_format": {"type": "json_object"}  # Enable JSON mode
        }
        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(GROQ_API_ENDPOINT, headers=headers, json=body)
                response.raise_for_status()
                data = response.json()
                # Adjust parsing based on GROQ API's actual response structure
                # Assuming similar to OpenAI's API for demonstration
                llm_output = data.get('choices', [{}])[0].get('message', {}).get('content', '')
                if not llm_output:
                    logger.error("LLM response is empty.")
                    return None
                return LLMResponse.parse_raw(json.dumps(json.loads(llm_output)))
            except (httpx.HTTPError, ValueError, json.JSONDecodeError) as e:
                logger.error("LLM Request failed or invalid JSON: %s", e)
                logger.debug("Raw response: %s", response.text if 'response' in locals() else "No response")
                return None

async def send_llm_request_with_backoff(prompt: str, max_retries: int = 5) -> Optional[LLMResponse]:
    """
    Send a request to the LLM with exponential backoff in case of rate limiting (429 errors).
    """
    delay = 2  # Start with a 2-second delay
    for attempt in range(max_retries):
        try:
            response = await send_llm_request(prompt)
            if response:
                return response
            else:
                raise ValueError("Empty or invalid response from LLM.")
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 429:
                logger.warning(
                    "LLM request hit rate limit (429). Attempt %s/%s. Retrying in %s seconds.",
                    attempt + 1, max_retries, delay
                )
                await asyncio.sleep(delay)
                delay *= 2  # Exponential backoff
            else:
                logger.error(
                    "LLM Request failed with status %s: %s",
                    e.response.status_code, e
                )
                break  # Exit on non-rate-limited errors
        except Exception as e:
            logger.error("LLM Request failed: %s", e)
            break  # Exit on other errors
    logger.error("Exceeded max retries for LLM request")
    return None

def initialize_agents() -> List[Dict]:
    """
    Initialize agents with random positions and empty memory, and insert them into Supabase.
    """
    agents = []
    try:
        supabase.table("agents").delete().neq("id", -1).execute()  # Clear existing agents
        for i in range(NUM_AGENTS):
            agent = {
                "id": i,
                "name": f"agent{i}",
                "x": random.randint(0, GRID_SIZE - 1),
                "y": random.randint(0, GRID_SIZE - 1),
                "memory": ""  # Initialize with empty memory
            }
            agents.append(agent)
            # Insert into Supabase
            supabase.table("agents").insert({
                "id": agent["id"],
                "name": agent["name"],
                "x": agent["x"],
                "y": agent["y"],
                "memory": agent["memory"]
            }).execute()
        logger.info("Initialized Agents:")
        for agent in agents:
            logger.info(agent)
    except Exception as e:
        logger.error("Failed to initialize agents: %s", e)
        raise
    return agents

def update_agent_position(agent: Dict, movement: str):
    """
    Update the agent's position based on the movement command.
    """
    if movement == "x+1":
        agent["x"] = (agent["x"] + 1) % GRID_SIZE
    elif movement == "x-1":
        agent["x"] = (agent["x"] - 1) % GRID_SIZE
    elif movement == "y+1":
        agent["y"] = (agent["y"] + 1) % GRID_SIZE
    elif movement == "y-1":
        agent["y"] = (agent["y"] - 1) % GRID_SIZE
    elif movement == "stay":
        pass  # No movement
    else:
        logger.warning(
            "Invalid movement command '%s' for agent %s. Staying in place.",
            movement, agent['id']
        )

async def perform_step(step: int):
    """
    Perform a simulation step:
    1. Fetch all agents.
    2. For each agent, process message, memory, and movement.
    3. Update agent positions based on movement commands.
    """
    agents = fetch_all_agents()
    agent_responses = {}

    for agent in agents:
        await process_agent(step, agent, agents, agent_responses)

    # After all agents have responded, handle movements
    for agent in agents:
        movement = agent_responses.get(agent["id"], "stay")
        update_agent_position(agent, movement)
        try:
            # Update position in Supabase
            supabase.table("agents").update({
                "x": agent["x"],
                "y": agent["y"]
            }).eq("id", agent["id"]).execute()
            # Insert movement into Supabase
            supabase.table("movements").insert({
                "step": step,
                "agent_id": agent["id"],
                "movement": movement
            }).execute()
            logger.info("Agent %s moved %s to (%s, %s)", agent["id"], movement, agent["x"], agent["y"])
        except Exception as e:
            logger.error("Failed to update movement for agent %s: %s", agent["id"], e)

async def process_agent(step: int, agent: Dict, agents: List[Dict], agent_responses: Dict):
    """
    Process an individual agent for a simulation step:
    1. Fetch received messages.
    2. Generate and send a message.
    3. Update memory.
    4. Determine movement.
    """
    received_messages = fetch_messages(step, agent, agents)
    
    # Construct Message Generation Prompt
    message_prompt = construct_prompt(MESSAGE_GENERATION_PROMPT, agent, received_messages)
    # Generate Message
    message_response = await send_llm_request_with_backoff(message_prompt)
    message_content = message_response.message if message_response else ""

    if message_content:
        try:
            supabase.table("messages").insert({
                "step": step,
                "sender_id": agent["id"],
                "content": message_content
            }).execute()
            logger.info("Agent %s sent message: %s", agent["id"], message_content)
        except Exception as e:
            logger.error("Failed to insert message for agent %s: %s", agent["id"], e)

    # Construct Memory Generation Prompt
    memory_prompt = construct_prompt(MEMORY_GENERATION_PROMPT, agent, received_messages)
    # Generate Memory
    memory_response = await send_llm_request_with_backoff(memory_prompt)
    updated_memory = memory_response.memory if memory_response else agent.get("memory", "")

    try:
        supabase.table("agents").update({
            "memory": updated_memory
        }).eq("id", agent["id"]).execute()
        logger.info("Agent %s updated memory.", agent["id"])
    except Exception as e:
        logger.error("Failed to update memory for agent %s: %s", agent["id"], e)

    # Construct Movement Generation Prompt
    movement_prompt = construct_prompt(MOVEMENT_GENERATION_PROMPT, agent, received_messages)
    # Generate Movement
    movement_response = await send_llm_request_with_backoff(movement_prompt)
    movement = movement_response.movement if movement_response else "stay"

    agent_responses[agent["id"]] = movement

def fetch_all_agents() -> List[Dict]:
    """
    Fetch all agents from Supabase.
    """
    try:
        response = supabase.table("agents").select("*").execute()
        return response.data
    except Exception as e:
        logger.error("Failed to fetch agents: %s", e)
        return []

def fetch_messages(step: int, agent: Dict, agents: List[Dict]) -> List[str]:
    """
    Fetch the latest messages from nearby agents up to the previous step.
    """
    nearby_agents = get_nearby_agents(agent, agents)
    messages = []
    for nearby in nearby_agents:
        try:
            # Fetch the latest message from this nearby agent up to the previous step
            response = supabase.table("messages") \
                .select("content") \
                .eq("sender_id", nearby["id"]) \
                .lte("step", step - 1) \
                .order("step", desc=True) \
                .limit(1) \
                .execute()
            if response.data:
                messages.append(response.data[0]["content"])
        except Exception as e:
            logger.error(
                "Failed to fetch messages for agent %s from agent %s: %s",
                agent["id"], nearby["id"], e
            )
    if not messages:
        messages.append("No Messages")
    return messages

# ---------------------- Simulation Status Management ----------------------

def get_simulation_status() -> Dict:
    """
    Retrieve the current simulation status from Supabase.
    If not present, initialize it.
    """
    try:
        response = supabase.table("simulation").select("*").eq("id", 1).execute()
        if response.data:
            return response.data[0]
        else:
            # Initialize simulation status if not present
            supabase.table("simulation").insert({
                "id": 1,
                "current_step": 0,
                "status": "stopped"
            }).execute()
            return {"id": 1, "current_step": 0, "status": "stopped"}
    except Exception as e:
        logger.error("Failed to fetch simulation status: %s", e)
        raise

def update_simulation_status(current_step: int, status: str):
    """
    Update the simulation status in Supabase.
    """
    try:
        supabase.table("simulation").update({
            "current_step": current_step,
            "status": status
        }).eq("id", 1).execute()
        logger.info("Simulation status updated to '%s' at step %s.", status, current_step)
    except Exception as e:
        logger.error("Failed to update simulation status: %s", e)

# ---------------------- API Endpoints ----------------------

@app.post("/reset")
@limiter.limit("10/minute")  # Example rate limit for /reset
async def reset_simulation(request: Request):
    """
    Reset the simulation by clearing all agents, messages, and movements,
    and setting the simulation status to 'stopped' at step 0.
    """
    try:
        # Clear dependent tables first to avoid foreign key constraints
        supabase.table("movements").delete().neq("id", -1).execute()
        supabase.table("messages").delete().neq("id", -1).execute()
        supabase.table("agents").delete().neq("id", -1).execute()
        # Reset simulation status
        supabase.table("simulation").update({
            "current_step": 0,
            "status": "stopped"
        }).eq("id", 1).execute()
        logger.info("Simulation has been reset.")
        return JSONResponse(content={"status": "Simulation reset successfully."})
    except Exception as e:
        logger.error("Failed to reset simulation: %s", e)
        raise HTTPException(status_code=500, detail="Failed to reset simulation.")

@app.post("/start")
@limiter.limit("10/minute")  # Example rate limit for /start
async def start_simulation(request: Request):
    """
    Start the simulation by initializing agents and setting the simulation status to 'running'.
    """
    try:
        status = get_simulation_status()
        if status["status"] == "running":
            logger.warning("Attempted to start simulation, but it is already running.")
            raise HTTPException(status_code=400, detail="Simulation is already running.")
        # Initialize agents
        initialize_agents()
        # Update simulation status
        update_simulation_status(current_step=0, status="running")
        logger.info("Simulation has been started.")
        return JSONResponse(content={"status": "Simulation started successfully."})
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.error("Failed to start simulation: %s", e)
        raise HTTPException(status_code=500, detail="Failed to start simulation.")

@app.post("/step")
@limiter.limit("60/minute")  # Example rate limit for /step
async def perform_steps(request: Request, step_request: StepRequest):
    """
    Perform a specified number of simulation steps.
    """
    try:
        status = get_simulation_status()
        if status["status"] != "running":
            logger.warning("Attempted to perform steps, but simulation is not running.")
            raise HTTPException(status_code=400, detail="Simulation is not running.")
        
        steps_to_perform = step_request.steps
        if steps_to_perform < 1:
            logger.warning("Invalid number of steps requested: %s", steps_to_perform)
            raise HTTPException(status_code=400, detail="Number of steps must be at least 1.")
        if status["current_step"] + steps_to_perform > MAX_STEPS:
            steps_to_perform = MAX_STEPS - status["current_step"]
            if steps_to_perform <= 0:
                logger.warning("Maximum number of steps reached.")
                raise HTTPException(status_code=400, detail="Maximum number of steps reached.")
        
        for _ in range(steps_to_perform):
            current_step = get_simulation_status()["current_step"] + 1
            await perform_step(current_step)
            update_simulation_status(current_step=current_step, status="running")
            if current_step >= MAX_STEPS:
                update_simulation_status(current_step=current_step, status="stopped")
                logger.info("Maximum number of steps reached. Simulation stopped.")
                break
        final_step = get_simulation_status()["current_step"]
        logger.info("Performed %s step(s). Current step: %s.", steps_to_perform, final_step)
        return JSONResponse(content={
            "status": f"Performed {steps_to_perform} step(s).",
            "current_step": final_step,
            "max_steps": MAX_STEPS
        })
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.error("Failed to perform steps: %s", e)
        raise HTTPException(status_code=500, detail="Failed to perform steps.")

@app.post("/stop")
@limiter.limit("10/minute")  # Example rate limit for /stop
async def stop_simulation(request: Request):
    """
    Stop the simulation by setting the simulation status to 'stopped'.
    """
    try:
        status = get_simulation_status()
        if status["status"] != "running":
            logger.warning("Attempted to stop simulation, but it is not running.")
            raise HTTPException(status_code=400, detail="Simulation is not running.")
        # Update simulation status
        update_simulation_status(current_step=status["current_step"], status="stopped")
        logger.info("Simulation has been stopped.")
        return JSONResponse(content={"status": "Simulation stopped successfully."})
    except Exception as e:
        logger.error("Failed to stop simulation: %s", e)
        raise HTTPException(status_code=500, detail="Failed to stop simulation.")

# ---------------------- Run the App ----------------------

# To run the app locally for testing, use the command:
# uvicorn main:app --host 0.0.0.0 --port 8000

# On Vercel, deploy this script as a serverless function following Vercel's deployment guidelines.
